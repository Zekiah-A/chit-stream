<!DOCTYPE html>
<html>
<head>
    <title>Chit-Stream</title>
    <style>
        * { box-sizing: border-box; }
        body {
            margin: 0px;
            padding: 0px;
            overflow-y: auto;
            overflow-x: hidden;
            top: 0;
            left: 0;
            position: absolute;
            width: 100%;
            height: 100%;
            font-family: Arial, Helvetica, sans-serif;
            background-image: url(./creo.png);
            color: white;
        }
        .stream-views {
            display: flex;
            column-gap: 8px;
            align-items: center;
        }
        .vid-container {
            position: relative;
            border: 1px solid gray;
            box-shadow: 0px 0px 4px gray;
            display: inline-block;
            min-height: 320px;
            border-radius: 8px;
            overflow: clip;
        }
        .vid-container > div {
            position: absolute;
            left: 0;
            bottom: 0;
            background: #626262a3;
            padding: 4px;
            border-radius: 0px 8px 0px 0px;
            color: white;
            backdrop-filter: blur(5px);
        }

        .pipeline-section {
            min-width: 256px;
            display: flex;
            flex-direction: column;
            align-self: stretch;
        }
        .pipeline-container {
            flex-grow: 1;
            padding: 8px;
            flex-direction: row;
            column-gap: 8px;
            display: flex;
            position: relative;
            width: 100%;
        }
        .pipeline-items-container {
            display: flex;
            column-gap: 16px;
            overflow-x: auto;
        }
        .pipeline-item {
            padding: 8px;
            border: 1px solid #ffffff3b;
            border-radius: 8px;
            backdrop-filter: blur(10px);
            background: linear-gradient(to bottom right, #fff0 80%, #b5b2b275);
            user-select: none;
            min-width: 276px;
            height: 274px;
        }
        .dropdown {
            position: absolute;
            margin: 0px;
            padding-left: 0;
            border-radius: 4px;
            backdrop-filter: blur(8px);
            box-shadow: 0px 0px 8px #404040;
            padding-right: 0;
            padding-top: 8px;
            padding-bottom: 8px;
            display: flex;
            list-style-type: none;
            width: max-content;
            z-index: 1;
        }
        .dropdown > li {
            user-select: none;
            padding-left: 16px;
            padding-right: 16px;
            padding-top: 8px;
            padding-bottom: 8px;
        }
        .dropdown > li:hover {
            background-color: #e3e3e33e;
        }
        .dropdown-title {
            margin-left: 8px;
            margin-top: 0px;
            margin-bottom: 0px;
            user-select: none;
        }
    </style>
    <script>var exports = {};</script>
    <script src="./lib/gputext.min.js"></script>
    <script src="./lib/gputext-webgl.min.js"></script>
    <script src="./lib/van-1.2.4.nomodule.min.js"></script>
    <script src="./lib/van-x.nomodule.min.js"></script>
</head>
<body>
    <div class="stream-views">
        <div class="vid-container">
            <video id="rawPreviewVideo" autoplay></video>
            <div>Raw source video</div>
        </div>
        <div class="vid-container">
            <canvas id="previewCanvas" autoplay></canvas>
            <div>Stream composite preview</div>
        </div>
    </div>
    <div class="pipeline-section" id="pipelineSection">
        <h4 style="margin: 0;">Render pipeline</h4>
    </div>
    <button onclick="startStream()">Start streaming</button>
    <button onclick="watchStream()">Start watching</button>
</body>
<script>
    const { button, div, li, ul, h4, p, input, svg, path, select, option } = van.tags
    const gl = previewCanvas.getContext("webgl2")
    const ws = new WebSocket("ws://localhost:3000")
    ws.binaryType = "arraybuffer"

    // Standard shader methods
	function loadShader(gl, type, source) {
		const shader = gl.createShader(type)
		gl.shaderSource(shader, source)
		gl.compileShader(shader)
		if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
			console.error("Failed to compile shader:", gl.getShaderInfoLog(shader))
			gl.deleteShader(shader)
			return null
		}

		return shader
	}

	function compileShaderProgram(gl, vertexSource, fragmentSource) {
		const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vertexSource)
		const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fragmentSource)

		const program = gl.createProgram()
		gl.attachShader(program, vertexShader)
		gl.attachShader(program, fragmentShader)
		gl.linkProgram(program)

		if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
			console.error("Failed to init shader:", gl.getProgramInfoLog(program))
			return null
		}
		
		return program
	}

    function bindBufferPositionAttrib(gl, buffer, vertexPositionAttrib) {
        const components = 2
        const type = gl.FLOAT
        const normalize = false
        const stride = 0 // Ignore, use components & type to determine byte stride
        const offset = 0 // Start from buffer start

        gl.bindBuffer(gl.ARRAY_BUFFER, buffer)
        gl.vertexAttribPointer(vertexPositionAttrib, components, type, normalize, stride, offset)
        gl.enableVertexAttribArray(vertexPositionAttrib)
    }

    function createPositionBuffer(positionsArr) {
        const buffer = gl.createBuffer()
        gl.bindBuffer(gl.ARRAY_BUFFER, buffer)
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positionsArr), gl.STATIC_DRAW)

        return buffer
    }

    // Effect shader definitions
    class StandardEffect {
        #videoTexture

        constructor() {
            this.vertex = `
                attribute vec4 a_vertexPosition;
                attribute vec2 a_texCoord;
                varying vec2 v_texCoord;

                void main()
                {
                    gl_Position = a_vertexPosition;
                    v_texCoord = a_texCoord;
                }
            `
            this.fragment = `
                precision mediump float;
                uniform sampler2D u_videoTexture;
                varying vec2 v_texCoord;

                void main()
                {
                    gl_FragColor = texture2D(u_videoTexture, v_texCoord);
                }
            `
            this._videoTexture = null
        }

        set videoTexture(value) {
            if (this.videoTextureAttrib) {
                this._videoTexture = value
                gl.uniform1i(this.videoTextureAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get videoTexture() {
            return this._videoTexture
        }

        exposes() { return div("This effect can't be configured :(") }
        frame() { /* No-op */ }
        destruct() { /* No-op */ }

        bindAttribs() {
            this.vertexPosAttrib = gl.getAttribLocation(this.program, "a_vertexPosition")
            this.vertexPosBuffer = createPositionBuffer([ 1.0,1.0, -1.0,1.0, 1.0,-1.0, -1.0,-1.0 ])
            bindBufferPositionAttrib(gl, this.vertexPosBuffer, this.vertexPosAttrib)

            this.texCoordAttrib = gl.getAttribLocation(this.program, "a_texCoord")
            this.texCoordBuffer = createPositionBuffer([ 1.0,0.0, 0.0,0.0, 1.0,1.0, 0.0,1.0 ]) // UV coordinates, BL, BR, TL, TR
            bindBufferPositionAttrib(gl, this.texCoordBuffer, this.texCoordAttrib)

            this.videoTextureAttrib = gl.getUniformLocation(this.program, "u_videoTexture")
            gl.uniform1i(this.videoTextureAttrib, this._videoTexture)
        }
    }

    class ImplosionEffect extends StandardEffect {
        #implosionCenter
        #implosionStrength

        constructor() {
            super()
            this.fragment = `
                precision mediump float;
                uniform sampler2D u_videoTexture;
                varying vec2 v_texCoord;

                uniform vec2 u_implosionCenter;
                uniform float u_implosionStrength;

                void main()
                {
                    // Calculate the vector from the current fragment to the implosion center
                    vec2 offset = v_texCoord - u_implosionCenter;
                    
                    // Calculate the distance from the implosion center
                    float distance = length(offset);
                    
                    // Apply the implosion effect
                    vec2 distortedTexCoord = v_texCoord - (offset * (1.0 / (1.0 + u_implosionStrength * distance)));

                    gl_FragColor = texture2D(u_videoTexture, distortedTexCoord);
                }
            `
            this._implosionCenter = { x: 0.5, y: 0.5 }
            this._implosionStrength = 1
        }

        set implosionCenter(value) {
            if (this.implosionCenterAttrib) {
                this._implosionCenter = value
                gl.uniform2f(this.implosionCenterAttrib, value.x, value.y)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get implosionCenter() {
            return this._implosionCenter
        }

        set implosionStrength(value) {
            if (this.implosionStrengthAttrib) {
                this._implosionStrength = value
                gl.uniform1f(this.implosionStrengthAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get implosionStrength() {
            return this._implosionStrength
        }

        exposes() {
            return div(
                div({style: "display: flex;"},
                div({style: "width: 78px;"}, "Strength"),
                    input({type: "range", step: "any", min: "-10", max: "10", value: this.implosionStrength,
                        oninput: (e) => this.implosionStrength = e.target.value})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Centre X"),
                    input({type: "range", step: "any", min: "0", max: "1", value: this.implosionCenter.x,
                        oninput: (e) => this.implosionCenter = { x: e.target.value, y: this.implosionCenter.y }}),
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Centre Y"),
                    input({type: "range", step: "any", min: "0", max: "1", value: this.implosionCenter.y,
                        oninput: (e) => this.implosionCenter = { x: this.implosionCenter.x, y: e.target.value }}),
                )
            )
        }

        bindAttribs() {
            super.bindAttribs()
            this.implosionCenterAttrib = gl.getUniformLocation(this.program, "u_implosionCenter");
            gl.uniform2f(this.implosionCenterAttrib, this._implosionCenter.x, this._implosionCenter.y) 

            this.implosionStrengthAttrib = gl.getUniformLocation(this.program, "u_implosionStrength")
            gl.uniform1f(this.implosionStrengthAttrib, this._implosionStrength)
        }
    }

    class SkinSmoothEffect extends StandardEffect {
        constructor() {
            super()
            this.fragment = `
                vec4 gaussian()
                {
                    float pi2 = 6.28318530718;
        
                    float Directions = 16.0; // BLUR DIRECTIONS (Default 16.0 - More is better but slower)
                    float Quality = 3.0; // BLUR QUALITY (Default 4.0 - More is better but slower)
                    float Size = 8.0; // BLUR SIZE (Radius)
                
                    vec2 Radius = Size / iResolution.xy;
                    
                    // Normalized pixel coordinates (from 0 to 1)
                    vec2 uv = fragCoord / iResolution.xy;
                    // Pixel colour
                    vec4 Color = texture(iChannel0, uv);
                    
                    // Blur calculations
                    for (float d=0.0; d < pi2; d += pi2 / Directions)
                    {
                        for (float i = 1.0 / Quality; i <= 1.0; i += 1.0 / Quality)
                        {
                            Color += texture(iChannel0, uv+vec2(cos(d), sin(d)) * Radius * i);		
                        }
                    }
                    
                    Color /= Quality * Directions - 15.0;
                    fragColor =  Color;
                }

                vec4 overlay(vec4 a, vec4 b)
                {
                    vec4 x = vec4(2.0) * a * b;
                    vec4 y = vec4(1.0) - vec4(2.0) * (vec4(1.0)-a) * (vec4(1.0)-b);
                    vec4 result;
                    result.r = mix(x.r, y.r, float(a.r > 0.5));
                    result.g = mix(x.g, y.g, float(a.g > 0.5));
                    result.b = mix(x.b, y.b, float(a.b > 0.5));
                    result.a = mix(x.a, y.a, float(a.a > 0.5));
                    return result;
                }
            `
        }

        bindAttribs() {
            super.bindAttribs()
        }
    }

    class FilterEffect extends StandardEffect {
        #brightness
        #contrast
        #saturation
        #hue

        constructor() {
            super()
            this.fragment = `
                precision mediump float;

                uniform sampler2D u_videoTexture;
                uniform float u_brightness;
                uniform float u_contrast;
                uniform float u_saturation;
                uniform float u_hue;

                varying vec2 v_texCoord;

                void main() {
                    vec4 color = texture2D(u_videoTexture, v_texCoord);

                    // Adjust brightness
                    color.rgb += (u_brightness - 1.0);

                    // Adjust contrast
                    color.rgb = (color.rgb - 0.5) * u_contrast + 0.5;

                    // Adjust saturation
                    float gray = dot(color.rgb, vec3(0.299, 0.587, 0.114));
                    color.rgb = mix(vec3(gray), color.rgb, u_saturation);

                    // Adjust hue
                    /*float angle = u_hue * 3.14159265359; // Convert hue to radians
                    float s = sin(angle);
                    float c = cos(angle);
                    vec3 rgb = vec3(
                        c + (1.0 - c) / 3.0,
                        1.0 / 3.0 * (1.0 - c) - sqrt(1.0 / 3.0) * s,
                        1.0 / 3.0 * (1.0 - c) + sqrt(1.0 / 3.0) * s
                    );
                    color.rgb = mat3(
                        rgb.x, rgb.x, rgb.x,
                        rgb.z, rgb.x - 2.0 * rgb.z, rgb.z,
                        rgb.z, rgb.z, rgb.y
                    ) * color.rgb;*/

                    gl_FragColor = color;
                }
            `
            this._brightness = 1.0
            this._contrast = 1.0
            this._saturation = 1.0
            this._hue = 0.0
        }

        set brightness(value) {
            if (this.brightnessAttrib) {
                this._brightness = value
                gl.uniform1f(this.brightnessAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get brightness() {
            return this._brightness
        }

        set contrast(value) {
            if (this.contrastAttrib) {
                this._contrast = value
                gl.uniform1f(this.contrastAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get contrast() {
            return this._contrast
        }

        set saturation(value) {
            if (this.saturationAttrib) {
                this._saturation = value
                gl.uniform1f(this.saturationAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get saturation() {
            return this._saturation
        }

        set hue(value) {
            if (this.hueAttrib) {
                this._hue = value
                gl.uniform1f(this.hueAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get hue() {
            return this._hue
        }

        exposes() {
            return div(
                div({style: "display: flex;"},
                div({style: "width: 78px;"}, "Brightness"),
                    input({type: "range", step: "any", min: "0", max: "2", value: this.brightness,
                        oninput: (e) => this.brightness = e.target.value})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Contrast"),
                    input({type: "range", step: "any", min: "0", max: "2", value: this.contrast,
                        oninput: (e) => this.contrast = e.target.value}),
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Hue"),
                    input({type: "range", step: "any", min: "0", max: "2", value: this.hue,
                        oninput: (e) => this.hue = e.target.value}),
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Saturation"),
                    input({type: "range", step: "any", min: "0", max: "2", value: this.saturation,
                        oninput: (e) => this.saturation = e.target.value}),
                )
            )
        }

        bindAttribs() {
            super.bindAttribs()
            this.brightnessAttrib = gl.getUniformLocation(this.program, "u_brightness");
            gl.uniform1f(this.brightnessAttrib, this._brightness)
            this.contrastAttrib = gl.getUniformLocation(this.program, "u_contrast")
            gl.uniform1f(this.contrastAttrib, this._contrast)
            this.saturationAttrib = gl.getUniformLocation(this.program, "u_saturation")
            gl.uniform1f(this.saturationAttrib, this._saturation)
            this.hueAttrib = gl.getUniformLocation(this.program, "u_hue")
            gl.uniform1f(this.hueAttrib, this._hue)
        }
    }

    class ImageOverlay extends StandardEffect {
        constructor() {
            super()
            this.vertex = `
                attribute vec4 a_vertexPosition;
                attribute vec2 a_texCoord;
                varying vec2 v_texCoord;

                void main()
                {
                    gl_Position = a_vertexPosition;
                    v_texCoord = a_texCoord;
                }
            `
            this.fragment = `
                precision mediump float;
                uniform sampler2D u_videoTexture;
                varying vec2 v_texCoord;

                void main()
                {
                    gl_FragColor = texture2D(u_videoTexture, v_texCoord);
                }
            `
            this.image = null
            this.transform = [ 1.0,1.0, -1.0,1.0, 1.0,-1.0, -1.0,-1.0 ]
        }

        exposes() {
            return div(
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "X"),    
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Y"),
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Width"),    
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Height"),
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;flex-direction:column;"},
                    h4({style:"margin-top: 8px;margin-bottom: 4px;"}, "Image:"),
                    input({type:"file"})
                )
            )
        }
    }

    class CaptureEffect extends StandardEffect {
        constructor() {
            super()
            this.fragment = `
                precision mediump float;
                uniform sampler2D u_videoTexture;
                uniform sampler2D u_inputTexture;
                uniform float u_opacity;
                uniform vec2 u_position;
                varying vec2 v_texCoord;

                void main()
                {
                    vec2 translatedTexCoord = v_texCoord + u_position;
                    float mask = step(0.0, translatedTexCoord.x) * step(translatedTexCoord.x, 1.0) *
                        step(0.0, translatedTexCoord.y) * step(translatedTexCoord.y, 1.0);

                    vec4 behindTex = texture2D(u_videoTexture, v_texCoord);
                    vec4 inputTex = texture2D(u_inputTexture, translatedTexCoord);
                    gl_FragColor = mix(behindTex, inputTex, u_opacity * mask);
                }
            `
            this._inputTexture = null
            this._opacity = 1.0
            this.inactive = true
            this._flipX = false
            this._flipY = false
            this._position = { x: 0, y: 0 }
        }

        set opacity(value) {
            if (this.opacityAttrib) {
                this._opacity = value
                gl.uniform1f(this.opacityAttrib, value)
            }
            else throw new Error("Shader effect must be bound first with attribute")
        }
        get opacity() {
            return this._opacity
        }
        get width() {
            return this._width
        }
        get height() {
            return this._height
        }
        get flipX() {
            return this._flipX
        }
        get flipY() {
            return this._flipY
        }
        get position() {
            return this._position
        }
        set position(value) {
            if (this.positionAttrib) {
                this._position = value
                gl.uniform2f(this.positionAttrib, value.x, value.y)
            }
        }

        frame() {
            gl.activeTexture(gl.TEXTURE1)
            gl.bindTexture(gl.TEXTURE_2D, this._inputTexture)
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, this._width, this._height, 0, gl.RGBA, gl.UNSIGNED_BYTE, rawPreviewVideo)

            // Fix later
            gl.uniform1i(this.inputTextureAttrib, 1)
        }

        destruct() {
            rawPreviewVideo.srcObject = null
        }

        exposes() {
            return div(
                h4({style: "margin-top: 8px;margin-bottom: 4px;"}, "Transform"),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "X"),    
                    input({type: "range", step: "any", min: "-10", max: "10", value: this._position.x,
                        oninput: (e) => this.position = { x: e.target.value, y: this._position.y }})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Y"),
                    input({type: "range", step: "any", min: "-10", max: "10", value: this._position.y,
                        oninput: (e) => this.position = { x: this._position.x, y: e.target.value }})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Width"),    
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Height"),
                    input({type: "range", step: "any", min: "-10", max: "10", value: 0})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Opacity"),
                    input({type: "range", step: "any", min: "0", max: "1", value: this._opacity,
                        oninput: (e) => this.opacity = e.target.value})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Flip X"),
                    input({type: "checkbox", value: this._flipX,
                        /*oninput: (e) => this.flipX = e.target.value*/})
                ),
                div({style: "display: flex;"},
                    div({style: "width: 78px;"}, "Flip Y"),
                    input({type: "checkbox", value: this._flipY,
                        /*oninput: (e) => this.flipY = e.target.value*/})
                ),
                h4({style: "margin-top: 8px;margin-bottom: 4px;"}, "Source"),
                select(
                    option({value: "320x240"}, "320x240"),
                    option({value: "640x480"}, "640x480"),
                    option({value: "1280x720"}, "1280x720"),
                    option({value: "1920x1080"}, "1920x1080")
                )
            )
        }

        bindAttribs() {
            super.bindAttribs()
            this.positionAttrib = gl.getUniformLocation(this.program, "u_position");
            gl.uniform2f(this.positionAttrib, this._position.x, this._position.y)

            this.inputTextureAttrib = gl.getUniformLocation(this.program, "u_inputTexture")
            gl.uniform1i(this.inputTextureAttrib, this._inputTexture)

            this.opacityAttrib = gl.getUniformLocation(this.program, "u_opacity")
            gl.uniform1f(this.opacityAttrib, this._opacity)
        }
    }

    class CameraInput extends CaptureEffect {
        constructor() {
            super()
            if (!navigator.mediaDevices.getUserMedia) {
                throw new Error("Error - Media devices not found", e)
                return
            }
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                if (stream == null) {
                    throw new Error("Error - Failed acquiring permissions!", e)
                    return
                }

                //gl.clear(gl.COLOR_BUFFER_BIT)
                rawPreviewVideo.srcObject = stream
                rawPreviewVideo.addEventListener("play", () => {
                    this._width = rawPreviewVideo.videoWidth
                    this._height = rawPreviewVideo.videoHeight
                    previewCanvas.width = Math.max(this._width, previewCanvas.width)
                    previewCanvas.height = Math.max(this._height, previewCanvas.height)

                    this._inputTexture = gl.createTexture()
                    gl.bindTexture(gl.TEXTURE_2D, this._inputTexture)
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR)
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR)
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, this._width, this._height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null)
                    this.inactive = false
                })
            }).catch(e => {
                throw new Error("Error - Failed acquiring video media! " + e)
            })
        }
    }

    class ScreenInput extends CaptureEffect {
        constructor() {
            super()
            if (!navigator.mediaDevices.getDisplayMedia) {
                throw new Error("Error - Media devices not found", e)
                return
            }
            this.displayMediaOptions = {
                video: {
                    displaySurface: "browser",
                },
                audio: {
                    suppressLocalAudioPlayback: false,
                },
                preferCurrentTab: false,
                selfBrowserSurface: "exclude",
                systemAudio: "include",
                surfaceSwitching: "include",
                monitorTypeSurfaces: "include",
            }
            navigator.mediaDevices.getDisplayMedia(this.displayMediaOptions).then((stream) => {
                if (stream == null) {
                    throw new Error("Error - Failed acquiring permissions!", e)
                    return
                }

                //gl.clear(gl.COLOR_BUFFER_BIT)
                rawPreviewVideo.srcObject = stream
                rawPreviewVideo.addEventListener("play", () => {
                    this._width = rawPreviewVideo.videoWidth
                    this._height = rawPreviewVideo.videoHeight
                    previewCanvas.width = Math.max(this._width, previewCanvas.width)
                    previewCanvas.height = Math.max(this._height, previewCanvas.height)

                    this._inputTexture = gl.createTexture()
                    gl.bindTexture(gl.TEXTURE_2D, this._inputTexture)
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR)
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR)
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, this._width, this._height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null)
                    this.inactive = false
                })
            }).catch(e => {
                throw new Error("Error - Failed acquiring video media! " + e)
            })
        }
    }

    const standardEffect = new StandardEffect()
    const inputShaders = {
        camera: CameraInput,
        screen: ScreenInput
    }
    const effectShaders = {
        implosion: ImplosionEffect,
        filter: FilterEffect
    }
    const overlayShaders = {
        image: ImageOverlay
    }

    function useEffectShader(shaderDefinition) {
        let program = shaderDefinition.program
        if (!program) {
            program = compileShaderProgram(gl, shaderDefinition.vertex, shaderDefinition.fragment)
            shaderDefinition.program = program
            gl.useProgram(program)
            shaderDefinition.bindAttribs()
        }
        else {
            gl.useProgram(program)
        }
        return shaderDefinition
    }

    const EffectOverlayPipeline = (pipeline) => {
        const pipelineState = vanX.reactive(pipeline)

        const EffectOverlayItem = (itemState, deleter, parentContainer) => {
            const effect = itemState.val
            const deleteThis = function() { effect.destruct(); deleter() }
            let dragging = false
            let leftOffset = 0
            let topOffset = 0

            const dragRegion = div({style: "display: flex;flex-grow: 1;justify-content: center; cursor: grab;",
                onmousedown: e => {
                    const itemPos = thisItem.getBoundingClientRect()
                    leftOffset = e.clientX - itemPos.left
                    topOffset = e.clientY - itemPos.top

                    thisItem.style.left = thisItem.offsetLeft + "px"
                    thisItem.style.top = thisItem.offsetTop + "px"

                    dragRegion.style.cursor = "grabbing"
                    thisItem.style.boxShadow = "rgba(89, 89, 89, 0.61) 0px 0px 16px"
                    thisItem.style.position = "absolute"
                    thisItem.style.zIndex = "2"
                    dragging = true
                },
                innerHTML:`<svg xmlns="http://www.w3.org/2000/svg" height="20" viewbox="0 -960 960 960" width="20">
                    <path fill="white" d="M360-160q-33 0-56.5-23.5T280-240q0-33 23.5-56.5T360-320q33 0 56.5 23.5T440-240q0 33-23.5 56.5T360-160Zm240 0q-33 0-56.5-23.5T520-240q0-33 23.5-56.5T600-320q33 0 56.5 23.5T680-240q0 33-23.5 56.5T600-160ZM360-400q-33 0-56.5-23.5T280-480q0-33 23.5-56.5T360-560q33 0 56.5 23.5T440-480q0 33-23.5 56.5T360-400Zm240 0q-33 0-56.5-23.5T520-480q0-33 23.5-56.5T600-560q33 0 56.5 23.5T680-480q0 33-23.5 56.5T600-400ZM360-640q-33 0-56.5-23.5T280-720q0-33 23.5-56.5T360-800q33 0 56.5 23.5T440-720q0 33-23.5 56.5T360-640Zm240 0q-33 0-56.5-23.5T520-720q0-33 23.5-56.5T600-800q33 0 56.5 23.5T680-720q0 33-23.5 56.5T600-640Z"></path>
                </svg>`}
            )

            function resetDrag(e) {
                thisItem.style.left = thisItem.offsetLeft + "px"
                thisItem.style.top = thisItem.offsetTop + "px"
                thisItem.style.boxShadow = "none"
                dragRegion.style.cursor = "grab"
                thisItem.style.position = "static"
                thisItem.style.zIndex = "0"
                dragging = false
            }

            const thisItemHeader = div({style: "display: flex;height: 20px;"},
                h4({class:"dropdown-title"}, effect.constructor.name),
                dragRegion,
                div({style:"cursor:pointer;",
                    onclick: () => deleteThis(),
                    innerHTML: `<svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20">
                        <path fill="white" d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/>
                    </svg>`}),
            )
            const thisItem = div({
                    class: "pipeline-item",
                    onmousemove: e => {
                        if (!dragging) return
                        const containerPos = parentContainer.getBoundingClientRect()
                        thisItem.style.left = (e.clientX - containerPos.left - leftOffset) + "px"
                        thisItem.style.top = (e.clientY - containerPos.top - topOffset) + "px"
                    },
                    onmouseleave: resetDrag,
                    onmouseup: resetDrag,
                    onscroll: e => {
                        if (e.target.scrollTop != 0) {
                            thisItemHeader.style.backdropFilter = "blur(8px)"
                            thisItemHeader.style.boxShadow = "#4f46464f 0px 4px 8px"
                        }
                        else {
                            thisItemHeader.style.backdropFilter = "none"
                            thisHeader.style.boxShadow = "none"
                        }
                    }
                },
                thisItemHeader,
                div({style: "margin-top: 16px;margin-left: 8px;margin-right: 8px;overflow-y: auto;max-height: calc(100% - 28px);"}, effect.exposes())
            )
            return thisItem
        }

        const dropdown = ul({
                class: "dropdown",
                style: "display: none;",
                onmouseleave: e => dropdown.style.display = "none"
            },
            h4({class:"dropdown-title"}, "Create input"),
            Object.keys(inputShaders)
            .map(name => li({onclick: e => {
                    pipelineState.push(new inputShaders[name]())
                    dropdown.style.display = "none"
                }}, name[0].toUpperCase() + name.slice(1) + " input")),
            h4({class:"dropdown-title"}, "Create effect"),
            Object.keys(effectShaders)
                .map(name => li({onclick: e => {
                    pipelineState.push(new effectShaders[name]())
                    dropdown.style.display = "none"
                }}, name[0].toUpperCase() + name.slice(1) + " effect")),
            h4({class:"dropdown-title"}, "Create overlay"),
            Object.keys(overlayShaders)
                .map(name => li({onclick: e => {
                    pipelineState.push(new overlayShaders[name]())
                    dropdown.style.display = "none"
                }}, name[0].toUpperCase() + name.slice(1) + " overlay")),
        )
    
        const pipelineItems = vanX.list(div, pipelineState, (itemState, deleter) => EffectOverlayItem(itemState, deleter, pipelineItems))
        pipelineItems.className = "pipeline-items-container"
        const pipelineContainer = div({class: "pipeline-container"},
            pipelineItems,
            button({
                onclick: e => {
                    dropdown.style.display = "block"
                    dropdown.style.left = (e.offsetX + e.target.offsetLeft + 8) + "px"
                    dropdown.style.top = (e.offsetY + e.target.offsetTop + 8) + "px"
                },
                style: "height: 64px; align-self: center; position: relative;"
            }, "+ Add new"),
        )

        van.add(pipelineContainer, dropdown)
        return pipelineContainer
    }

    let pipeline = []
    van.add(pipelineSection, EffectOverlayPipeline(pipeline))
    
    // Stream methods
    async function startStream() {
        gl.clear(gl.COLOR_BUFFER_BIT)
        const width = 640
        const height = 480
        gl.viewport(0, 0, gl.canvas.width, gl.canvas.height)

        let frame = 0
        function captureFrame() {
            const framebuffer = gl.createFramebuffer()
            gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer)
            
            // TODO: Find some way to use single FB so ABAB is not needed
            function createFramebufferTex() {
                const fbTexture = gl.createTexture()
                gl.bindTexture(gl.TEXTURE_2D, fbTexture)
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR)
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR)
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null)
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, fbTexture, 0)
                return fbTexture
            }

            const fbTexture1 = createFramebufferTex()
            const fbTexture2 = createFramebufferTex()
            let currentTexture = fbTexture1


            if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
                console.error("Framebuffer is not complete")
                return
            }
            gl.bindFramebuffer(gl.FRAMEBUFFER, null) // unbind

            function pipelineStep(effect) {
                const currentEffect = useEffectShader(effect);

                // Hand last frame texture to shader
                gl.activeTexture(gl.TEXTURE0)
                gl.bindTexture(gl.TEXTURE_2D, currentTexture)
                currentEffect.videoTexture = 0

                // Let effect do its per frame operations
                currentEffect.frame()

                // Hand next frame texture
                gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer)
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D,
                    currentTexture === fbTexture1 ? fbTexture2 : fbTexture1, 0)
                gl.clear(gl.COLOR_BUFFER_BIT)
                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4)

                // Swap textures for the next iteration
                currentTexture = currentTexture === fbTexture1 ? fbTexture2 : fbTexture1
            }


            if (pipeline.length != 0) {
                for (const effect of pipeline) {
                    if (effect && !effect.inactive) {
                        pipelineStep(effect) // can be holey
                    }
                }
            }
            else {
                pipelineStep(standardEffect)
            }

            // Render the final result
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

            /*
            const imageData = new Uint8Array(width * height * 4)
            gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, imageData)
            const binaryData = new Uint8Array(imageData.buffer)
            const packet = new Uint8Array(binaryData.byteLength + 1)
            packet.set(binaryData, 1)
            ws.send(packet)
            */
            // Free resources
            gl.deleteTexture(fbTexture1)
            gl.deleteTexture(fbTexture2)
            gl.deleteFramebuffer(framebuffer)
            // Proceed
            requestAnimationFrame(captureFrame)
            frame++
        }
        captureFrame()
        console.log("Started streaming")
    }

    async function watchStream() {
        let imageData = null

        ws.onmessage = async function({ data }) {
            const u8Data = new Uint8ClampedArray(data)

            switch (u8Data[0]) {
                case 0: {
                    let width = 1280
                    let height = 720
                    let fps = 0

                    canvas.width = width
                    canvas.height = height
                    
                    const dummyFrame = new Uint8ClampedArray(width * height * 4)
                    imageData = new ImageData(dummyFrame, width, height)
                    rawPreviewVideo.srcObject = canvas.captureStream(fps)
                    break
                }
                case 1: {
                    imageData.data.set(u8Data.subarray(1), 0) 
                    context.putImageData(imageData, 0, 0)
                    break
                }
            }
        }

        console.log("Started observing stream")
    }
</script>
</html>
